{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOX01qtb3pAGUGh2kozdLuy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InvoLab101/10conv-poc/blob/main/10conversation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "ev5bXjxcWtPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Install dependencies"
      ],
      "metadata": {
        "id": "KyQ-sKEF10nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install diskcache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_kzyPyB101q",
        "outputId": "a1efc15c-e1b0-4073-f145-4a6a2d1bde0b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Collecting diskcache\n",
            "  Downloading diskcache-5.6.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: diskcache\n",
            "Successfully installed diskcache-5.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### load data"
      ],
      "metadata": {
        "id": "BptSitXmx_Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import openai\n",
        "import logging\n",
        "import diskcache\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "conversation_folder = '/content/drive/MyDrive/10conversations'  # Change this to your desired directory\n",
        "conversation_files = os.listdir(conversation_folder)\n",
        "QUESTIONS = [\n",
        "    'Did the HDA welcome the customer to the bank, introduced himself/herself by name, and attained customer\\'s name immediately? (Yes or No)',\n",
        "    'Did the HDA acknowledge the customer’s request, paraphrased back to demonstrate active listening and understanding of the customer’s request or needs? (Yes or No)',\n",
        "    'Did the HDA demonstrate empathy of customer\\'s concern (Yes or No)',\n",
        "    'Did the HDA make strong/confident customer advocacy statements? (Yes or No)',\n",
        "    'Did the HDA promote passcode for future interactions? (Yes or No or NA)',\n",
        "    'Did the HDA gain permissions to ask questions and make value added recommendations? (Yes or No)',\n",
        "    'Did the HDA solve the customer’s request efficiently and position alternatives with customer benefits and educate customer as needed? (Yes or No)',\n",
        "    'Was a call transfer absolutely necessary to resolve the customer’s request? (Yes or No or NA)',\n",
        "    'Did the HDA add value by promoting or offering or acknowledging digital banking use and services? (Yes or No)',\n",
        "    'Did the HDA use benefit statements to explain why the product or service is of value to the customer’s needs and ask for the business? (Yes or No)',\n",
        "    'Did the HDA accurately recap the conversation, provide a clear explanation of next steps setting expectations, and check for additional needs? (Yes or No)',\n",
        "    'Did the HDA thank the customer by name for their loyalty to the bank and close with appreciation for their business? (Yes or No)'\n",
        "    ]\n",
        "\n",
        "conversations = []\n",
        "for filename in conversation_files:\n",
        "    with open(os.path.join(conversation_folder, filename), \"r\") as file:\n",
        "        conversation = file.read()\n",
        "        conversations.append(conversation)\n",
        "\n",
        "data = pd.DataFrame({\"Conversation\": conversations})\n",
        "\n",
        "print(f\"loaded {len(data['Conversation'])} conversations\")\n",
        "print(f\"loaded {len(QUESTIONS)} questions\")\n",
        "\n",
        "with open(\"/content/drive/MyDrive/work_asu/config.json\", \"r\") as config_file:\n",
        "    config = json.load(config_file)\n",
        "openai.api_key = config[\"openai_api_key\"]\n",
        "print('openAi key loaded')\n",
        "\n",
        "cache = diskcache.Cache(\"/content/drive/MyDrive/work_asu\")\n",
        "print(\"cache loaded\")\n",
        "\n",
        "def engineerPrompt(conversation):\n",
        "    prompt = '''\n",
        "    below is a customer service call between a Help Desk Agent(HDA) and Customer(C)\n",
        "    {}\n",
        "    based on the conversation above, answer these questions:\n",
        "    {}\n",
        "    Only give me the answers in order and put them in a list\n",
        "\n",
        "    '''.format(conversation, '\\n'.join(QUESTIONS))\n",
        "    logging.debug(\"engineered prompt: {}\".format(prompt))\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def getResponse(conversation):\n",
        "    response = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      prompt=engineerPrompt(conversation),\n",
        "      temperature=0,\n",
        "      max_tokens=50,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "    )\n",
        "    logging.info(response)\n",
        "    return response.choices[0].text"
      ],
      "metadata": {
        "id": "cX0dViTVXx1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c60c6bd-66a3-4af7-b5ae-1f1b1cebf804"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "loaded 10 conversations\n",
            "loaded 12 questions\n",
            "openAi key loaded\n",
            "cache loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### help functions"
      ],
      "metadata": {
        "id": "cBobx6H3yUQI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0ZvroZ-aI_O"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QVTPWXuO_nwn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "NYG1oS_dikD2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-hNGul3kisHU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}